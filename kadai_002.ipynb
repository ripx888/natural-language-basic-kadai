{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru_poerlD5bq",
        "outputId": "e5042e33-c9bd-45dd-9b1c-5d0ade383ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib import request\n",
        "import re\n",
        "\n",
        "url = 'https://www.aozora.gr.jp/cards/000148/files/2371_13943.html'\n",
        "response = request.urlopen(url)\n",
        "soup = BeautifulSoup(response, 'html.parser')\n",
        "response.close()\n",
        "\n",
        "main_text = soup.find('div', class_='main_text')\n",
        "\n",
        "\n",
        "tags_to_delete = main_text.find_all(['rp', 'rt'])\n",
        "for tag in tags_to_delete:\n",
        "    tag.decompose()\n",
        "\n",
        "main_text = main_text.get_text()\n",
        "main_text = re.sub(r\"[\\u3000\\n\\r]\", \"\", main_text)\n",
        "\n",
        "url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
        "response = request.urlopen(url)\n",
        "soup = BeautifulSoup(response, 'html.parser')\n",
        "response.close()\n",
        "\n",
        "stopwords_text = soup.text\n",
        "stopwords_list = stopwords_text.split(\"\\r\\n\")\n",
        "stopwords_list = [word for word in stopwords_list if word]\n",
        "\n",
        "\n",
        "split_text_list =  ['私', 'は', '今日', '、', 'スーパー', 'で', '沢山', 'の', 'お', '菓子', 'を', '買っ', 'た', '。']\n",
        "result_text_list = [split_text for split_text in split_text_list if split_text not in stopwords_list]\n",
        "\n",
        "print(result_text_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU2BkNQMTvSV",
        "outputId": "0cc5b2e1-de08-4098-b799-88103d0af968"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['は', '今日', '、', 'スーパー', 'で', '沢山', 'の', 'お', '菓子', 'を', '買っ', 'た', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hCXUm5Xs187u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}